# ğŸ¤– **GLM AI é›†æˆå®Œæ•´æ–¹æ¡ˆ**

**API æä¾›æ–¹ï¼š** æ™ºè°±æ¸…è¨€ (GLM)  
**ç›®æ ‡ï¼š** åœ¨ç¾å®¹é™¢ç®¡ç†ç³»ç»Ÿä¸­é›†æˆ AI åŠŸèƒ½  
**æ—¶é—´ï¼š** 3-5 å¤©å®Œæˆç¬¬ä¸€é˜¶æ®µ  
**éš¾åº¦ï¼š** â­â­ ç®€å•

---

## **âœ… GLM API å‡†å¤‡**

æ‚¨éœ€è¦å‡†å¤‡çš„ä¿¡æ¯ï¼š

```
â–¡ GLM API Key          â†’ ä»æ™ºè°±æ¸…è¨€æ§åˆ¶å°è·å–
â–¡ API Endpoint         â†’ https://open.bigmodel.cn/api/paas/v4/chat/completions
â–¡ Model Name           â†’ glm-4 æˆ– glm-3-turbo
â–¡ é€Ÿç‡é™åˆ¶ï¼ˆRPMï¼‰      â†’ æ ¹æ®æ‚¨çš„å¥—é¤
```

**è·å–æ­¥éª¤ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰ï¼š**
1. è®¿é—® https://open.bigmodel.cn
2. æ³¨å†Œè´¦æˆ·
3. åˆ›å»º API Key
4. è®°ä¸‹æ‚¨çš„ Key

---

## **ğŸ“‹ ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒ AI åŠŸèƒ½ï¼ˆ3-5 å¤©ï¼‰**

### **1ï¸âƒ£ AI èŠå¤©åŠ©æ‰‹ï¼ˆç¬¬ 1-2 å¤©ï¼‰**

**åŠŸèƒ½ï¼š**
- å›ç­”ç¾å®¹ç›¸å…³é—®é¢˜
- æä¾›æœåŠ¡å»ºè®®
- é¢„çº¦è¾…å¯¼
- äº§å“æ¨è

**é›†æˆæ–‡ä»¶æ¸…å•ï¼š**
```
1. src/services/aiService.ts       (æ–°å»º)
   â””â”€ GLM API è°ƒç”¨å°è£…

2. src/components/AIChat.tsx       (æ–°å»ºæˆ–ä¿®æ”¹)
   â””â”€ èŠå¤©ç•Œé¢ç»„ä»¶

3. src/context/AIContext.tsx       (æ–°å»º)
   â””â”€ AI çŠ¶æ€ç®¡ç†

4. ç¯å¢ƒå˜é‡é…ç½®
   â””â”€ .env ä¸­æ·»åŠ  GLM_API_KEY
```

**æˆæœ¬ï¼š**
- ä»£ç ç¼–å†™ï¼š4-6 å°æ—¶
- æµ‹è¯•è°ƒè¯•ï¼š2-3 å°æ—¶
- æ€»è®¡ï¼š6-9 å°æ—¶

---

### **2ï¸âƒ£ å®¢æˆ·æµå¤±é¢„è­¦ï¼ˆç¬¬ 2-3 å¤©ï¼‰**

**åŠŸèƒ½ï¼š**
- åˆ†æå®¢æˆ·é¢„çº¦å†å²
- è¯†åˆ«æµå¤±é£é™©å®¢æˆ·
- ç”Ÿæˆé¢„è­¦å»ºè®®
- æ¨èæ¿€åŠ±æ–¹æ¡ˆ

**å®ç°æ–¹å¼ï¼š**
```
1. åˆ†æå¼•æ“ï¼ˆsrc/services/predictionService.tsï¼‰
   - è®¡ç®—å®¢æˆ·æ´»è·ƒåº¦åˆ†æ•°
   - é¢„æµ‹æµå¤±é£é™©
   - ç”ŸæˆæŠ¥å‘Š

2. GLM æ¨èï¼ˆsrc/services/recommendationService.tsï¼‰
   - è°ƒç”¨ GLM ç”Ÿæˆæ¿€åŠ±å»ºè®®
   - ç”Ÿæˆè¥é”€æ–‡æ¡ˆ
```

**æˆæœ¬ï¼š**
- ä»£ç ç¼–å†™ï¼š3-4 å°æ—¶
- ç®—æ³•ä¼˜åŒ–ï¼š2-3 å°æ—¶
- æ€»è®¡ï¼š5-7 å°æ—¶

---

### **3ï¸âƒ£ æ™ºèƒ½æ’ç­æ¨èï¼ˆç¬¬ 3-4 å¤©ï¼‰**

**åŠŸèƒ½ï¼š**
- åˆ†æé¢„çº¦æ•°æ®
- æ¨èæœ€ä¼˜æ’ç­
- æˆæœ¬ä¼˜åŒ–å»ºè®®

**å®ç°æ–¹å¼ï¼š**
```
1. æ•°æ®åˆ†æï¼ˆsrc/services/schedulingService.tsï¼‰
   - ç»Ÿè®¡é¢„çº¦åˆ†å¸ƒ
   - è®¡ç®—å‘˜å·¥æ•ˆç‡

2. GLM ä¼˜åŒ–
   - è®© GLM åˆ†ææ•°æ®å¹¶ç»™å‡ºå»ºè®®
   - ç”Ÿæˆæ’ç­ä¼˜åŒ–æŠ¥å‘Š
```

---

### **4ï¸âƒ£ åŠ¨æ€å®šä»·å»ºè®®ï¼ˆç¬¬ 4-5 å¤©ï¼‰**

**åŠŸèƒ½ï¼š**
- åˆ†æå¸‚åœºéœ€æ±‚
- å»ºè®®è°ƒæ•´ä»·æ ¼
- ä¼˜åŒ–æ”¶ç›Š

---

## **ğŸ’» å®ç°æ­¥éª¤**

### **æ­¥éª¤ 1ï¼šå®‰è£…ä¾èµ–ï¼ˆ5 åˆ†é’Ÿï¼‰**

```bash
npm install @zhipu/sdk
# æˆ–ä½¿ç”¨ HTTP å®¢æˆ·ç«¯ï¼ˆå·²æœ‰ axiosï¼‰
```

### **æ­¥éª¤ 2ï¼šåˆ›å»º GLM æœåŠ¡æ¨¡å—**

**æ–‡ä»¶ï¼š`src/services/aiService.ts`**

```typescript
import axios from 'axios';

const GLM_API_KEY = process.env.REACT_APP_GLM_API_KEY || process.env.VITE_GLM_API_KEY;
const GLM_ENDPOINT = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

export interface AIMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface AIResponse {
  content: string;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

class AIService {
  private conversationHistory: AIMessage[] = [];

  async chat(userMessage: string): Promise<AIResponse> {
    this.conversationHistory.push({
      role: 'user',
      content: userMessage,
    });

    try {
      const response = await axios.post(
        GLM_ENDPOINT,
        {
          model: 'glm-4',
          messages: this.conversationHistory,
          temperature: 0.7,
          top_p: 0.7,
          max_tokens: 1000,
        },
        {
          headers: {
            'Authorization': `Bearer ${GLM_API_KEY}`,
            'Content-Type': 'application/json',
          },
        }
      );

      const assistantMessage = response.data.choices[0].message.content;
      this.conversationHistory.push({
        role: 'assistant',
        content: assistantMessage,
      });

      return {
        content: assistantMessage,
        usage: response.data.usage,
      };
    } catch (error: any) {
      console.error('GLM API é”™è¯¯:', error.message);
      throw new Error(`AI æœåŠ¡é”™è¯¯: ${error.message}`);
    }
  }

  clearHistory(): void {
    this.conversationHistory = [];
  }

  async analyzeLossRisk(customerData: any): Promise<string> {
    const prompt = `
    åˆ†æä»¥ä¸‹å®¢æˆ·æ•°æ®ï¼Œè¯„ä¼°å®¢æˆ·æµå¤±é£é™©ã€‚
    å®¢æˆ·æ•°æ®: ${JSON.stringify(customerData)}
    
    è¯·æä¾›ï¼š
    1. æµå¤±é£é™©ç­‰çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. é£é™©åŸå› åˆ†æ
    3. å»ºè®®çš„æ¿€åŠ±æ–¹æ¡ˆ
    `;

    return (await this.chat(prompt)).content;
  }

  async optimizeSchedule(scheduleData: any): Promise<string> {
    const prompt = `
    æ ¹æ®ä»¥ä¸‹é¢„çº¦æ•°æ®ï¼Œå»ºè®®æœ€ä¼˜çš„å‘˜å·¥æ’ç­å®‰æ’ã€‚
    é¢„çº¦æ•°æ®: ${JSON.stringify(scheduleData)}
    
    è¯·æä¾›ï¼š
    1. æ¨èçš„æ’ç­æ–¹æ¡ˆ
    2. æˆæœ¬èŠ‚çœä¼°è®¡
    3. å®¢æˆ·æ»¡æ„åº¦é¢„æµ‹
    `;

    return (await this.chat(prompt)).content;
  }
}

export const aiService = new AIService();
export default aiService;
```

### **æ­¥éª¤ 3ï¼šç¯å¢ƒå˜é‡é…ç½®**

**æ–‡ä»¶ï¼š`.env`**

```
# GLM AI é…ç½®
VITE_GLM_API_KEY=your_glm_api_key_here
```

**æ–‡ä»¶ï¼š`vite.config.ts`** (å¦‚æœéœ€è¦)

```typescript
// ç¡®ä¿ç¯å¢ƒå˜é‡èƒ½è¢«æ­£ç¡®è¯»å–
export default defineConfig({
  define: {
    'process.env': process.env,
  },
  // ... å…¶ä»–é…ç½®
});
```

### **æ­¥éª¤ 4ï¼šåˆ›å»º AI èŠå¤©ç»„ä»¶**

**æ–‡ä»¶ï¼š`src/components/AIChat.tsx`**

```typescript
import React, { useState, useRef, useEffect } from 'react';
import { MessageCircle, Send, X } from 'lucide-react';
import aiService from '../services/aiService';

export const AIChat: React.FC = () => {
  const [messages, setMessages] = useState<Array<{role: string, content: string}>>([]);
  const [input, setInput] = useState('');
  const [isOpen, setIsOpen] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSendMessage = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim()) return;

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage = { role: 'user', content: input };
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      // è°ƒç”¨ GLM API
      const response = await aiService.chat(input);
      setMessages((prev) => [
        ...prev,
        { role: 'assistant', content: response.content }
      ]);
    } catch (error: any) {
      setMessages((prev) => [
        ...prev,
        { role: 'assistant', content: `é”™è¯¯: ${error.message}` }
      ]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div>
      {/* æµ®çª—æŒ‰é’® */}
      {!isOpen && (
        <button
          onClick={() => setIsOpen(true)}
          className="fixed bottom-4 right-4 bg-green-500 text-white p-4 rounded-full shadow-lg hover:bg-green-600 transition"
        >
          <MessageCircle size={24} />
        </button>
      )}

      {/* èŠå¤©çª—å£ */}
      {isOpen && (
        <div className="fixed bottom-4 right-4 w-96 bg-white rounded-lg shadow-xl border border-gray-200 flex flex-col h-96">
          {/* å¤´éƒ¨ */}
          <div className="bg-green-500 text-white p-4 flex justify-between items-center rounded-t-lg">
            <h3 className="font-bold">AI åŠ©æ‰‹</h3>
            <button onClick={() => setIsOpen(false)}>
              <X size={20} />
            </button>
          </div>

          {/* æ¶ˆæ¯åŒºåŸŸ */}
          <div className="flex-1 overflow-y-auto p-4 space-y-4">
            {messages.map((msg, idx) => (
              <div
                key={idx}
                className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
              >
                <div
                  className={`max-w-xs px-4 py-2 rounded-lg ${
                    msg.role === 'user'
                      ? 'bg-green-100 text-gray-800'
                      : 'bg-gray-100 text-gray-800'
                  }`}
                >
                  {msg.content}
                </div>
              </div>
            ))}
            {isLoading && (
              <div className="flex justify-start">
                <div className="bg-gray-100 px-4 py-2 rounded-lg">
                  AI æ€è€ƒä¸­...
                </div>
              </div>
            )}
            <div ref={messagesEndRef} />
          </div>

          {/* è¾“å…¥åŒºåŸŸ */}
          <form onSubmit={handleSendMessage} className="border-t p-4 flex gap-2">
            <input
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              placeholder="è¾“å…¥é—®é¢˜..."
              className="flex-1 border rounded px-3 py-2 focus:outline-none focus:ring-2 focus:ring-green-500"
              disabled={isLoading}
            />
            <button
              type="submit"
              disabled={isLoading}
              className="bg-green-500 text-white p-2 rounded hover:bg-green-600 disabled:opacity-50"
            >
              <Send size={20} />
            </button>
          </form>
        </div>
      )}
    </div>
  );
};

export default AIChat;
```

---

## **ğŸš€ ç«‹å³å¼€å§‹çš„ 3 ä¸ªæ­¥éª¤**

### **ç¬¬ 1 æ­¥ï¼šæ”¶é›† GLM ä¿¡æ¯ï¼ˆ5 åˆ†é’Ÿï¼‰**

```
â–¡ æ‚¨çš„ GLM API Key
â–¡ é€‰æ‹©æ¨¡å‹ï¼šglm-4 (æœ€å¥½) è¿˜æ˜¯ glm-3-turbo (ä¾¿å®œ)
â–¡ æ‚¨çš„ API é€Ÿç‡é™åˆ¶
```

### **ç¬¬ 2 æ­¥ï¼šæˆ‘åˆ›å»ºä»£ç ï¼ˆ2 å°æ—¶ï¼‰**

```
â–¡ åˆ›å»º aiService.ts
â–¡ åˆ›å»º AIChat.tsx ç»„ä»¶
â–¡ é›†æˆåˆ°ç°æœ‰åº”ç”¨
```

### **ç¬¬ 3 æ­¥ï¼šæµ‹è¯• + éƒ¨ç½²ï¼ˆ1 å°æ—¶ï¼‰**

```
â–¡ æœ¬åœ°æµ‹è¯•
â–¡ æäº¤ Git
â–¡ éƒ¨ç½²åˆ° Vercel
```

---

## **ğŸ’° æˆæœ¬ä¼°ç®—**

**GLM API è°ƒç”¨æˆæœ¬ï¼š**

```
glm-4 æ¨¡å‹:
  - è¾“å…¥: 0.01 å…ƒ/1000 tokens
  - è¾“å‡º: 0.05 å…ƒ/1000 tokens
  - å…è´¹é¢åº¦: æ¯æœˆ 3 ç™¾ä¸‡ tokens

glm-3-turbo:
  - è¾“å…¥: 0.0005 å…ƒ/1000 tokens
  - è¾“å‡º: 0.001 å…ƒ/1000 tokens
  - å…è´¹é¢åº¦: å……è¶³
```

**ç¤ºä¾‹æˆæœ¬ï¼š**
- æ¯æ¬¡èŠå¤©ï¼š0.01-0.05 å…ƒ
- 100 æ¬¡èŠå¤©ï¼š1-5 å…ƒ
- 1000 æ¬¡èŠå¤©ï¼š10-50 å…ƒ

---

## **ğŸ“… å®Œæ•´æ—¶é—´è¡¨**

```
ä»Šå¤©ï¼š
  âœ¨ æ”¶é›† GLM API Key
  âœ¨ åˆ›å»º aiService.ts

æ˜å¤©ï¼š
  âœ¨ åˆ›å»º AIChat ç»„ä»¶
  âœ¨ æœ¬åœ°æµ‹è¯•

åå¤©ï¼š
  âœ¨ æ·»åŠ æµå¤±é¢„è­¦åˆ†æ
  âœ¨ æ·»åŠ æ’ç­ä¼˜åŒ–

ç¬¬ 4 å¤©ï¼š
  âœ¨ æ·»åŠ å®šä»·ä¼˜åŒ–
  âœ¨ å…¨é¢æµ‹è¯•

ç¬¬ 5 å¤©ï¼š
  âœ¨ ä¼˜åŒ– + æ¸…ç†ä»£ç 
  âœ¨ éƒ¨ç½²åˆ° Vercel
  âœ¨ å‡†å¤‡æ¼”ç¤º
```

---

## **âœ… å‡†å¤‡å¥½äº†å—ï¼Ÿ**

**è¯·å‘Šè¯‰æˆ‘ï¼š**

```
1. æ‚¨çš„ GLM API Key
   â†’ æˆ–è€…å‘Šè¯‰æˆ‘åœ¨å“ªé‡Œè·å–

2. é€‰æ‹©æ¨¡å‹
   â˜ glm-4 (æœ€å¼ºå¤§ï¼Œæ¨è)
   â˜ glm-3-turbo (ä¾¿å®œå¿«é€Ÿ)

3. ä¼˜å…ˆçº§
   â˜ å…ˆåšèŠå¤©åŠ©æ‰‹
   â˜ å…¨éƒ¨åŠŸèƒ½ä¸€èµ·åš
```

---

**ä¸€æ—¦æ‚¨æä¾›ä¿¡æ¯ï¼Œæˆ‘ä»¬ç«‹å³å¼€å§‹é›†æˆï¼** ğŸš€

è¿™æ · 3-5 å¤©å†…ï¼Œæ‚¨å°±æœ‰äº†ä¸€ä¸ª**å®Œæ•´çš„ AI æ™ºèƒ½ç¾å®¹é™¢ç®¡ç†ç³»ç»Ÿ**ï¼
